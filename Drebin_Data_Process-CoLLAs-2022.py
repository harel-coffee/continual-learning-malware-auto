#!/usr/bin/env python
# coding: utf-8

# In[2]:


import random
random.seed(1)

import os, sys
import logging
import numpy as np
import time
from timeit import default_timer as timer
from datetime import datetime
from tqdm import tqdm
from collections import OrderedDict, Counter
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import LabelEncoder, MinMaxScaler


# In[8]:


def create_folder(name):
    if not os.path.exists(name):
        os.makedirs(name)

        
def sort_drebin_family_all(family_file, intermediate_folder,te_ratio):

    top18 = ['FakeInstaller', 'DroidKungFu', 'Plankton','Opfake', 'GinMaster', 
            'BaseBridge', 'Iconosys', 'Kmin', 'FakeDoc', 'Geinimi',
            'Adrd','DroidDream','MobileTx',
            'FakeRun','SendPay','Gappusin','Imlog','SMSreg']
    # 'LinuxLotoor' and'GoldDream' are missing in the sha256_family.csv metadata

    #sha_family_dict = {}
    #sha_timestamp_dict = {}

    train_shas, train_labels = [], []
    test_shas, test_labels = [], []
    for family in top18:
        shas, labels = [], []
        with open(family_file, 'r') as f:
            next(f)
            for line in f:
                sha, family_name = line.strip().split(',')
                if family == family_name:
                    family_int = top18.index(family)
                    #print(family_int)
                    labels.append(family_int)
                    shas.append(sha)

        print(f'Family {family} has {len(labels)} samples')
        test_num = int(len(labels) * te_ratio)
        #print(test_num)
        tr_shas = shas[0:-test_num]
        tr_labels = labels[0:-test_num]

        te_shas = shas[-test_num:]
        te_labels = labels[-test_num:]
        
        #print(len(tr_labels))
        #print(len(te_labels))  
        
        for i in range(len(tr_labels)):
            train_shas.append(tr_shas[i])
            train_labels.append(tr_labels[i])
            
        for j in range(len(te_labels)):
            test_shas.append(te_shas[j])
            test_labels.append(te_labels[j])
    logging.debug(f'train_shas: {len(train_shas)}, test_shas: {len(test_shas)}')
    
    print(f'train_shas: {len(train_shas)}, test_shas: {len(test_shas)}')
    

    return train_shas, test_shas, train_labels, test_labels   

def get_training_features(intermediate_folder, raw_feature_vectors_folder, train_shas):
    train_feature_names = set()
    for sha in train_shas:
        sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')
        lines = sys.stdin.readlines()
        for l in lines:
            if l != '\n':
                train_feature_names.add(l.strip())


    logging.info(f'# of features in training set: {len(train_feature_names)}')
    
    saved_train_feature_file = intermediate_folder + '/all_training_features.txt'
    with open(saved_train_feature_file, 'w') as f:
        for fea in train_feature_names:
            f.write(fea + '\n')
    print(f'Number of Training features before Variance Thresholding {len(train_feature_names)}')
    return list(train_feature_names)

def save_training_features(intermediate_folder, raw_feature_vectors_folder,
                                       train_shas, train_feature_names, train_labels):
    
    saved_train_vectors = os.path.join(intermediate_folder, f'drebin_family_all_train_full_feature_vectors.npz')
    #train_feature_names = list(train_feature_names)
    if not os.path.exists(saved_train_vectors):
        samples = len(train_shas)
        feas = len(train_feature_names)
        X = np.zeros((samples, feas))
        for sample_idx, sha in enumerate(train_shas):
            sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')
            lines = sys.stdin.readlines()
            for l in lines:
                if l != '\n':
                    fea_idx = train_feature_names.index(l.strip())
                    X[sample_idx][fea_idx] = 1

        y = np.array([int(label) for label in train_labels])
        np.savez_compressed(saved_train_vectors, X_train=X, y_train=y)
    
    return saved_train_vectors



def get_final_features(intermediate_folder, var_threshold, saved_train_vectors, train_feature_names):
    train_data = np.load(saved_train_vectors)
    X, y = train_data['X_train'], train_data['y_train']
    logging.debug(f'[drebin_family_all] before feature selection X shape: {X.shape}')
    selector = VarianceThreshold(var_threshold)
    X_select = selector.fit_transform(X)
    logging.debug(f'[drebin_family_all] after feature selection X_select shape: {X_select.shape}')
    
    print(f'Before feature selection X shape: {X.shape}')
    print(f'After feature selection X_select shape: {X_select.shape}')
    selected_feature_indices = selector.get_support(indices=True)
    # logging.debug(f'selected_feature_indices: {list(selected_feature_indices)}')
    selected_features = np.array(train_feature_names)[selected_feature_indices]

    ''' save selected features and corresponding feature vectors of training set '''
    saved_selected_feature_file = os.path.join(intermediate_folder, f'drebin_family_all_train_selected_features.txt')
    if not os.path.exists(saved_selected_feature_file):
        with open(saved_selected_feature_file, 'w') as fout:
            for fea in selected_features:
                fout.write(f'{fea}\n')
    saved_selected_vectors_file = os.path.join(intermediate_folder, f'drebin_family_all_train_final_feature_vectors.npz')
    if not os.path.exists(saved_selected_vectors_file):
        np.savez_compressed(saved_selected_vectors_file, X_train=X_select, y_train=y)

    return selected_features, saved_selected_vectors_file

        

def main():
    # download 'feature_vectors' from the Drebin data repository and put them into 'drebin_data' directory.
    raw_feature_vectors_folder = '/home/mr6564/Drebin_Data/feature_vectors'
    family_file = 'sha256_family.csv' #'drebin_data/sha256_family.csv'
    dataset_name = 'drebin'
    save_folder = 'collas_2022_drebin_processed'
    create_folder(save_folder)

    print('Preparing Drebin malware data...')

    intermediate_folder = save_folder

    var_threshold = 0.001
    test_ratio = 0.2

    max_len = 0

    X_tr, Y_tr = [], []
    X_te, Y_te = [], []

    family_start = time.time()

    train_shas, test_shas, train_labels, test_labels =                sort_drebin_family_all(family_file, intermediate_folder, test_ratio)  



    train_feature_names = get_training_features(intermediate_folder,
                                raw_feature_vectors_folder, train_shas)
    #print(train_feature_names)
    #print(len(train_shas)) 
    saved_train_vectors = save_training_features(intermediate_folder, raw_feature_vectors_folder,
                                           train_shas, train_feature_names, train_labels)

    # feature selection on the training set
    selected_features, saved_selected_vectors_file =                        get_final_features(intermediate_folder, var_threshold,
                                saved_train_vectors, train_feature_names)
    # generate the final data by saving feature vectors of both training and testing set
    samples = len(test_shas)
    feas = len(selected_features)
    selected_features = list(selected_features)  # numpy array does not have index method
    X_test = np.zeros((samples, feas))
    for sample_idx, sha in enumerate(test_shas):
        sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')
        lines = sys.stdin.readlines()
        for idx, l in enumerate(lines):
            if l != '\n':
                try:
                    fea_idx = selected_features.index(l.strip())
                    X_test[sample_idx][fea_idx] = 1
                except: # ignore unseen features.
                    pass
    y_test = np.array([int(label) for label in test_labels])

    train_data = np.load(saved_selected_vectors_file)
    X_train, y_train = train_data['X_train'], train_data['y_train']

    y_train, y_test = np.asarray(y_train), np.asarray(y_test)

    save_train_files =  './collas_2022_drebin_train_all.npz'
    save_test_files = './collas_2022_drebin_test_all.npz'

    np.savez_compressed(save_train_files, X_train=X_train, y_train=y_train)
    np.savez_compressed(save_test_files, X_test=X_test, y_test=y_test)


    print('\n\n')
    print(f'X_train_final : {X_train.shape}, y_train_final: {y_train.shape}')
    print(f'X_test_final: {X_test.shape}, y_test_final: {y_test.shape}')
    print(f'total data {(len(y_train) + len(y_test))}')




    family_end = time.time()
    print(f'\ntime elapsed time is {(family_end - family_start)/60} mins.')
    
main()


# In[ ]:




