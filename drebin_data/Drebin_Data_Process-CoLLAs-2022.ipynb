{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import os, sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, Counter\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Drebin malware data...\n",
      "Family FakeInstaller has 925 samples\n",
      "Family DroidKungFu has 667 samples\n",
      "Family Plankton has 625 samples\n",
      "Family Opfake has 613 samples\n",
      "Family GinMaster has 339 samples\n",
      "Family BaseBridge has 330 samples\n",
      "Family Iconosys has 152 samples\n",
      "Family Kmin has 147 samples\n",
      "Family FakeDoc has 132 samples\n",
      "Family Geinimi has 92 samples\n",
      "Family Adrd has 91 samples\n",
      "Family DroidDream has 81 samples\n",
      "Family MobileTx has 69 samples\n",
      "Family FakeRun has 61 samples\n",
      "Family SendPay has 59 samples\n",
      "Family Gappusin has 58 samples\n",
      "Family Imlog has 43 samples\n",
      "Family SMSreg has 41 samples\n",
      "train_shas: 3627, test_shas: 898\n",
      "Number of Training features before Variance Thresholding 8803\n",
      "Before feature selection X shape: (3627, 8803)\n",
      "After feature selection X_select shape: (3627, 2492)\n",
      "\n",
      "\n",
      "\n",
      "X_train_final : (3627, 2492), y_train_final: (3627,)\n",
      "X_test_final: (898, 2492), y_test_final: (898,)\n",
      "total data 4525\n",
      "\n",
      "time elapsed time is 0.06729995807011922 mins.\n"
     ]
    }
   ],
   "source": [
    "def create_folder(name):\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)\n",
    "\n",
    "        \n",
    "def sort_drebin_family_all(family_file, intermediate_folder,te_ratio):\n",
    "\n",
    "    top18 = ['FakeInstaller', 'DroidKungFu', 'Plankton','Opfake', 'GinMaster', \n",
    "            'BaseBridge', 'Iconosys', 'Kmin', 'FakeDoc', 'Geinimi',\n",
    "            'Adrd','DroidDream','MobileTx',\n",
    "            'FakeRun','SendPay','Gappusin','Imlog','SMSreg']\n",
    "    # 'LinuxLotoor' and'GoldDream' are missing in the sha256_family.csv metadata\n",
    "\n",
    "    #sha_family_dict = {}\n",
    "    #sha_timestamp_dict = {}\n",
    "\n",
    "    train_shas, train_labels = [], []\n",
    "    test_shas, test_labels = [], []\n",
    "    for family in top18:\n",
    "        shas, labels = [], []\n",
    "        with open(family_file, 'r') as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                sha, family_name = line.strip().split(',')\n",
    "                if family == family_name:\n",
    "                    family_int = top18.index(family)\n",
    "                    #print(family_int)\n",
    "                    labels.append(family_int)\n",
    "                    shas.append(sha)\n",
    "\n",
    "        print(f'Family {family} has {len(labels)} samples')\n",
    "        test_num = int(len(labels) * te_ratio)\n",
    "        #print(test_num)\n",
    "        tr_shas = shas[0:-test_num]\n",
    "        tr_labels = labels[0:-test_num]\n",
    "\n",
    "        te_shas = shas[-test_num:]\n",
    "        te_labels = labels[-test_num:]\n",
    "        \n",
    "        #print(len(tr_labels))\n",
    "        #print(len(te_labels))  \n",
    "        \n",
    "        for i in range(len(tr_labels)):\n",
    "            train_shas.append(tr_shas[i])\n",
    "            train_labels.append(tr_labels[i])\n",
    "            \n",
    "        for j in range(len(te_labels)):\n",
    "            test_shas.append(te_shas[j])\n",
    "            test_labels.append(te_labels[j])\n",
    "    logging.debug(f'train_shas: {len(train_shas)}, test_shas: {len(test_shas)}')\n",
    "    \n",
    "    print(f'train_shas: {len(train_shas)}, test_shas: {len(test_shas)}')\n",
    "    \n",
    "\n",
    "    return train_shas, test_shas, train_labels, test_labels   \n",
    "\n",
    "def get_training_features(intermediate_folder, raw_feature_vectors_folder, train_shas):\n",
    "    train_feature_names = set()\n",
    "    for sha in train_shas:\n",
    "        sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')\n",
    "        lines = sys.stdin.readlines()\n",
    "        for l in lines:\n",
    "            if l != '\\n':\n",
    "                train_feature_names.add(l.strip())\n",
    "\n",
    "\n",
    "    logging.info(f'# of features in training set: {len(train_feature_names)}')\n",
    "    \n",
    "    saved_train_feature_file = intermediate_folder + '/all_training_features.txt'\n",
    "    with open(saved_train_feature_file, 'w') as f:\n",
    "        for fea in train_feature_names:\n",
    "            f.write(fea + '\\n')\n",
    "    print(f'Number of Training features before Variance Thresholding {len(train_feature_names)}')\n",
    "    return list(train_feature_names)\n",
    "\n",
    "def save_training_features(intermediate_folder, raw_feature_vectors_folder,\n",
    "                                       train_shas, train_feature_names, train_labels):\n",
    "    \n",
    "    saved_train_vectors = os.path.join(intermediate_folder, f'drebin_family_all_train_full_feature_vectors.npz')\n",
    "    #train_feature_names = list(train_feature_names)\n",
    "    if not os.path.exists(saved_train_vectors):\n",
    "        samples = len(train_shas)\n",
    "        feas = len(train_feature_names)\n",
    "        X = np.zeros((samples, feas))\n",
    "        for sample_idx, sha in enumerate(train_shas):\n",
    "            sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')\n",
    "            lines = sys.stdin.readlines()\n",
    "            for l in lines:\n",
    "                if l != '\\n':\n",
    "                    fea_idx = train_feature_names.index(l.strip())\n",
    "                    X[sample_idx][fea_idx] = 1\n",
    "\n",
    "        y = np.array([int(label) for label in train_labels])\n",
    "        np.savez_compressed(saved_train_vectors, X_train=X, y_train=y)\n",
    "    \n",
    "    return saved_train_vectors\n",
    "\n",
    "\n",
    "\n",
    "def get_final_features(intermediate_folder, var_threshold, saved_train_vectors, train_feature_names):\n",
    "    train_data = np.load(saved_train_vectors)\n",
    "    X, y = train_data['X_train'], train_data['y_train']\n",
    "    logging.debug(f'[drebin_family_all] before feature selection X shape: {X.shape}')\n",
    "    selector = VarianceThreshold(var_threshold)\n",
    "    X_select = selector.fit_transform(X)\n",
    "    logging.debug(f'[drebin_family_all] after feature selection X_select shape: {X_select.shape}')\n",
    "    \n",
    "    print(f'Before feature selection X shape: {X.shape}')\n",
    "    print(f'After feature selection X_select shape: {X_select.shape}')\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    # logging.debug(f'selected_feature_indices: {list(selected_feature_indices)}')\n",
    "    selected_features = np.array(train_feature_names)[selected_feature_indices]\n",
    "\n",
    "    ''' save selected features and corresponding feature vectors of training set '''\n",
    "    saved_selected_feature_file = os.path.join(intermediate_folder, f'drebin_family_all_train_selected_features.txt')\n",
    "    if not os.path.exists(saved_selected_feature_file):\n",
    "        with open(saved_selected_feature_file, 'w') as fout:\n",
    "            for fea in selected_features:\n",
    "                fout.write(f'{fea}\\n')\n",
    "    saved_selected_vectors_file = os.path.join(intermediate_folder, f'drebin_family_all_train_final_feature_vectors.npz')\n",
    "    if not os.path.exists(saved_selected_vectors_file):\n",
    "        np.savez_compressed(saved_selected_vectors_file, X_train=X_select, y_train=y)\n",
    "\n",
    "    return selected_features, saved_selected_vectors_file\n",
    "\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # download 'feature_vectors' from the Drebin data repository and put them into 'drebin_data' directory.\n",
    "    raw_feature_vectors_folder = '/home/mr6564/Drebin_Data/feature_vectors'\n",
    "    family_file = 'sha256_family.csv' #'drebin_data/sha256_family.csv'\n",
    "    dataset_name = 'drebin'\n",
    "    save_folder = 'collas_2022_drebin_processed'\n",
    "    create_folder(save_folder)\n",
    "\n",
    "    print('Preparing Drebin malware data...')\n",
    "\n",
    "    intermediate_folder = save_folder\n",
    "\n",
    "    var_threshold = 0.001\n",
    "    test_ratio = 0.2\n",
    "\n",
    "    max_len = 0\n",
    "\n",
    "    X_tr, Y_tr = [], []\n",
    "    X_te, Y_te = [], []\n",
    "\n",
    "    family_start = time.time()\n",
    "\n",
    "    train_shas, test_shas, train_labels, test_labels =\\\n",
    "                sort_drebin_family_all(family_file, intermediate_folder, test_ratio)  \n",
    "\n",
    "\n",
    "\n",
    "    train_feature_names = get_training_features(intermediate_folder,\n",
    "                                raw_feature_vectors_folder, train_shas)\n",
    "    #print(train_feature_names)\n",
    "    #print(len(train_shas)) \n",
    "    saved_train_vectors = save_training_features(intermediate_folder, raw_feature_vectors_folder,\n",
    "                                           train_shas, train_feature_names, train_labels)\n",
    "\n",
    "    # feature selection on the training set\n",
    "    selected_features, saved_selected_vectors_file =\\\n",
    "                        get_final_features(intermediate_folder, var_threshold,\n",
    "                                saved_train_vectors, train_feature_names)\n",
    "    # generate the final data by saving feature vectors of both training and testing set\n",
    "    samples = len(test_shas)\n",
    "    feas = len(selected_features)\n",
    "    selected_features = list(selected_features)  # numpy array does not have index method\n",
    "    X_test = np.zeros((samples, feas))\n",
    "    for sample_idx, sha in enumerate(test_shas):\n",
    "        sys.stdin = open(f'{raw_feature_vectors_folder}/{sha}')\n",
    "        lines = sys.stdin.readlines()\n",
    "        for idx, l in enumerate(lines):\n",
    "            if l != '\\n':\n",
    "                try:\n",
    "                    fea_idx = selected_features.index(l.strip())\n",
    "                    X_test[sample_idx][fea_idx] = 1\n",
    "                except: # ignore unseen features.\n",
    "                    pass\n",
    "    y_test = np.array([int(label) for label in test_labels])\n",
    "\n",
    "    train_data = np.load(saved_selected_vectors_file)\n",
    "    X_train, y_train = train_data['X_train'], train_data['y_train']\n",
    "\n",
    "    y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "    save_train_files =  './collas_2022_drebin_train_all.npz'\n",
    "    save_test_files = './collas_2022_drebin_test_all.npz'\n",
    "\n",
    "    np.savez_compressed(save_train_files, X_train=X_train, y_train=y_train)\n",
    "    np.savez_compressed(save_test_files, X_test=X_test, y_test=y_test)\n",
    "\n",
    "\n",
    "    print('\\n\\n')\n",
    "    print(f'X_train_final : {X_train.shape}, y_train_final: {y_train.shape}')\n",
    "    print(f'X_test_final: {X_test.shape}, y_test_final: {y_test.shape}')\n",
    "    print(f'total data {(len(y_train) + len(y_test))}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    family_end = time.time()\n",
    "    print(f'\\ntime elapsed time is {(family_end - family_start)/60} mins.')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
