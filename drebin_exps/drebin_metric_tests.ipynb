{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "import visual_plt\n",
    "import utils\n",
    "import pandas as pd\n",
    "from param_stamp import get_param_stamp, get_param_stamp_from_args\n",
    "import evaluate\n",
    "from data import get_multitask_experiment, get_malware_multitask_experiment\n",
    "from encoder import Classifier\n",
    "from vae_models import AutoEncoder\n",
    "import callbacks as cb\n",
    "from train import train_cl\n",
    "from continual_learner import ContinualLearner\n",
    "from exemplars import ExemplarHandler\n",
    "from replayer import Replayer\n",
    "from param_values import set_default_values\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is used\n",
      "\n",
      "Preparing the data...\n",
      " --> drebin: 3627 training and 898 testing samples\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_feats_length, target_feats_length = 2492, 2500\n",
    "dataset_name = 'drebin'\n",
    "scenario = 'task'\n",
    "\n",
    "# Use cuda?\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"CUDA is {}used\".format(\"\" if cuda else \"NOT(!!) \"))\n",
    "\n",
    "\n",
    "# Prepare data for chosen experiment\n",
    "print(\"\\nPreparing the data...\")\n",
    "(train_datasets, test_datasets), config, classes_per_task = get_malware_multitask_experiment(\n",
    "name='splitMNIST', dataset_name=dataset_name, scenario=scenario, orig_feats_length=orig_feats_length,\\\n",
    "target_feats_length=target_feats_length, tasks=6,\n",
    "verbose=True, exception=True,\n",
    ")\n",
    "\n",
    "# config\n",
    "\n",
    "model = Classifier(\n",
    "    image_size=50, image_channels=1, classes=3,\n",
    "    fc_bn=True, excit_buffer=False,).to(device)\n",
    "\n",
    "model_save_path = './drebin_saved_models/6_class.pt'\n",
    "model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_per_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1595629427478/work/aten/src/THC/THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f9c21bed6c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_exemplars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allowed_classes=list(range(classes_per_task*i,\\\n\u001b[0;32m--> 148\u001b[0;31m         classes_per_task*(i+1))) if scenario==\"task\" else None) for i in range(task)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f9c21bed6c60>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_exemplars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allowed_classes=list(range(classes_per_task*i,\\\n\u001b[0;32m--> 148\u001b[0;31m         classes_per_task*(i+1))) if scenario==\"task\" else None) for i in range(task)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f9c21bed6c60>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dataset, task_classes, batch_size, test_size, verbose, allowed_classes, with_exemplars, no_task_mask, task)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#print(allowed_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# -break on [test_size] (if \"None\", full dataset is used)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1595629427478/work/aten/src/THC/THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "def validate(model, dataset, task_classes, batch_size=16, test_size=1024, verbose=True, allowed_classes=None,\n",
    "             with_exemplars=False, no_task_mask=False, task=None):\n",
    "    '''Evaluate precision (= accuracy or proportion correct) of a classifier ([model]) on [dataset].\n",
    "\n",
    "    [allowed_classes]   None or <list> containing all \"active classes\" between which should be chosen\n",
    "                            (these \"active classes\" are assumed to be contiguous)'''\n",
    "\n",
    "    # Set model to eval()-mode\n",
    "    mode = model.training\n",
    "    model.eval()\n",
    "\n",
    "    # Apply task-specifc \"gating-mask\" for each hidden fully connected layer (or remove it!)\n",
    "    if hasattr(model, \"mask_dict\") and model.mask_dict is not None:\n",
    "        if no_task_mask:\n",
    "            model.reset_XdGmask()\n",
    "        else:\n",
    "            model.apply_XdGmask(task=task)\n",
    "\n",
    "    # Loop over batches in [dataset]\n",
    "    data_loader = utils.get_data_loader(dataset, batch_size, cuda=model._is_on_cuda())\n",
    "    total_tested = total_correct = 0\n",
    "    \n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    y_predicts_scores = []\n",
    "    \n",
    "    normalized_scores = []\n",
    "    \n",
    "    \n",
    "    #print(allowed_classes)\n",
    "    for data, labels in data_loader:\n",
    "        # -break on [test_size] (if \"None\", full dataset is used)\n",
    "        if test_size:\n",
    "            if total_tested >= test_size:\n",
    "                break\n",
    "        # -evaluate model (if requested, only on [allowed_classes])\n",
    "        data, labels = data.to(model._device()), labels.to(model._device())\n",
    "        labels = labels - allowed_classes[0] if (allowed_classes is not None) else labels\n",
    "        #print(labels)\n",
    "        #print(allowed_classes)\n",
    "        with torch.no_grad():\n",
    "            if with_exemplars:\n",
    "                predicted = model.classify_with_exemplars(data, allowed_classes=allowed_classes)\n",
    "                # - in case of Domain-IL scenario, collapse all corresponding domains into same class\n",
    "                if max(predicted).item() >= model.classes:\n",
    "                    predicted = predicted % model.classes\n",
    "            else:\n",
    "                scores = model(data) if (allowed_classes is None) else model(data)[:, allowed_classes]\n",
    "                #print(labels, scores)\n",
    "                \n",
    "                '''\n",
    "                if get_valid_loss:\n",
    "                    # Calculate prediction loss\n",
    "                    if args.bce:\n",
    "                        # -binary prediction loss\n",
    "                        binary_targets = utils.to_one_hot(y.cpu(), y_hat.size(1)).to(y.device)\n",
    "                        if self.binaryCE_distill and (scores is not None):\n",
    "                            classes_per_task = int(y_hat.size(1) / task)\n",
    "                            binary_targets = binary_targets[:, -(classes_per_task):]\n",
    "                            binary_targets = torch.cat([torch.sigmoid(scores / self.KD_temp), binary_targets], dim=1)\n",
    "                        predL = None if y is None else F.binary_cross_entropy_with_logits(\n",
    "                            input=y_hat, target=binary_targets, reduction='none'\n",
    "                        ).sum(dim=1).mean()     #--> sum over classes, then average over batch\n",
    "                    else:\n",
    "                        # -multiclass prediction loss\n",
    "                        predL = None if y is None else F.cross_entropy(input=y_hat, target=y, reduction='mean')\n",
    "                '''\n",
    "\n",
    "                predicted_scores, predicted = torch.max(scores, 1)\n",
    "                \n",
    "                #print(task_classes)\n",
    "                if task_classes > 2:\n",
    "                    #print(predicted_scores.cpu().numpy())\n",
    "                    #print(list(predicted_scores.detach().cpu().numpy()))\n",
    "                    temp_scores = list(predicted_scores.detach().cpu().numpy())\n",
    "                    labs = list(labels.detach().cpu().numpy())\n",
    "                    #print(labs)\n",
    "                    #print(predicted_scores.shape)\n",
    "                    \n",
    "                    score_detached = scores.detach().cpu().numpy()\n",
    "                    \n",
    "                    for i_sample in score_detached:\n",
    "                        detached_i = i_sample\n",
    "                        if allowed_classes is not None:\n",
    "                            pre_normal_i = [(float(k)-min(detached_i))/(max(detached_i)-min(detached_i)) for k in detached_i]\n",
    "                            normal_i = [np.float(j)/sum(pre_normal_i) for j in pre_normal_i]\n",
    "                            normalized_scores.append(np.array(normal_i))\n",
    "                        else:\n",
    "                            normalized_scores.append(np.array(detached_i))\n",
    "                        \n",
    "                        #print(sum(normal_i))\n",
    "                        \n",
    "                    #normalized_scores = np.array(normalized_scores, dtype=np.float32)\n",
    "                    #print(roc_auc_score(labs, normalized_scores, multi_class=\"ovr\", average=\"weighted\"))\n",
    "                    #print(scores, sum(score_detached[0]))\n",
    "                    #print(roc_auc_score(labs, score_detached, multi_class=\"ovr\", average=\"weighted\"))\n",
    "                    y_predicts_scores.append((temp_scores))\n",
    "                else:\n",
    "                    y_predicts_scores += list(predicted.detach().cpu().numpy())\n",
    "                \n",
    "                \n",
    "                #print(roc_auc_score(np.array(list(labels.detach().cpu().numpy())),\n",
    "                #                    np.array(list(scores.detach().cpu().numpy())),\n",
    "                #                    multi_class=\"ovr\", average=\"weighted\"))\n",
    "                #print(roc_auc_score(np.array(list(labels.detach().cpu().numpy())),\\\n",
    "                #                np.array(list(predicted.detach().cpu().numpy())), average=\"weighted\"))\n",
    "                \n",
    "        # -update statistics\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_tested += len(data)\n",
    "        \n",
    "        correct_labels += list(labels.cpu().numpy())\n",
    "        predicted_labels += list(predicted.cpu().numpy())\n",
    "        \n",
    "    precision = total_correct / total_tested\n",
    "    #y_predicts_scores = np.array(y_predicts_scores,dtype=np.float64)\n",
    "    correct_labels = np.array(correct_labels)\n",
    "    \n",
    "    #print(y_predicts_scores)\n",
    "    normalized_scores = np.array(normalized_scores, dtype=np.float32)\n",
    "    print(len(normalized_scores))\n",
    "    \n",
    "    \n",
    "    #print(len(correct_labels), np.unique(correct_labels), len(y_predicts_scores))\n",
    "    \n",
    "    #print(correct_labels, y_predicts_scores)\n",
    "    #f1score = f1_score(correct_labels, np.array(predicted_labels), average='weighted')\n",
    "    #print(roc_auc_score(correct_labels, y_predicts_scores, average=\"weighted\"))\n",
    "    \n",
    "    rocscore = roc_auc_score(correct_labels, normalized_scores, multi_class=\"ovr\", average=\"weighted\")\n",
    "    #rocscore = roc_auc_score(correct_labels, y_predicts_scores, average=\"weighted\")\n",
    "    print(rocscore)\n",
    "    \n",
    "    \n",
    "    #print(f'F1 score {f1score}')\n",
    "    # Set model back to its initial mode, print result on screen (if requested) and return it\n",
    "    model.train(mode=mode)\n",
    "    #if verbose:\n",
    "    #     print('=> F1Score {:.3f}'.format(f1score))\n",
    "    return rocscore \n",
    "\n",
    "total_classes = 18\n",
    "task = 6\n",
    "task_classes = int(total_classes/task)\n",
    "precs = [validate(\n",
    "        model, test_datasets[i], task_classes, verbose=True, test_size=None, task=i+1, with_exemplars=False,\n",
    "        allowed_classes=list(range(classes_per_task*i,\\\n",
    "        classes_per_task*(i+1))) if scenario==\"task\" else None) for i in range(task)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1595629427478/work/aten/src/THC/THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e661f4e4933c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_exemplars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         allowed_classes=list(range(classes_per_task*i,\\\n\u001b[0;32m----> 5\u001b[0;31m         classes_per_task*(i+1))) if scenario==\"task\" else None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f9c21bed6c60>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dataset, task_classes, batch_size, test_size, verbose, allowed_classes, with_exemplars, no_task_mask, task)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#print(allowed_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# -break on [test_size] (if \"None\", full dataset is used)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1595629427478/work/aten/src/THC/THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "validate(\n",
    "        model, test_datasets[i], task_classes, verbose=True, test_size=None, task=i+1, with_exemplars=False,\n",
    "        allowed_classes=list(range(classes_per_task*i,\\\n",
    "        classes_per_task*(i+1))) if scenario==\"task\" else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "allowed_classes=[list(range(classes_per_task*i, classes_per_task*(i+1))) for i in range(3)]\n",
    "allowed_classes[2]\n",
    "\n",
    "\n",
    "current_testdata = copy.deepcopy(test_datasets[0])\n",
    "\n",
    "with_exemplars=False\n",
    "\n",
    "# Set model to eval()-mode\n",
    "mode = model.training\n",
    "model.eval()\n",
    "\n",
    "# Loop over batches in [dataset]\n",
    "data_loader = utils.get_data_loader(current_testdata, 128, cuda=model._is_on_cuda())\n",
    "total_tested = total_correct = 0\n",
    "\n",
    "correct_labels = []\n",
    "predicted_labels = []\n",
    "y_predicts_scores = []\n",
    "\n",
    "cnt = 0\n",
    "for data, labels in data_loader:\n",
    "\n",
    "    # -evaluate model (if requested, only on [allowed_classes])\n",
    "    data, labels = data.to(model._device()), labels.to(model._device())\n",
    "    #labels = labels - allowed_classes[0] if (allowed_classes is not None) else labels\n",
    "    labels = labels\n",
    "    #print(labels)\n",
    "    with torch.no_grad():\n",
    "        if with_exemplars:\n",
    "            predicted = model.classify_with_exemplars(data, allowed_classes=allowed_classes)\n",
    "            # - in case of Domain-IL scenario, collapse all corresponding domains into same class\n",
    "            if max(predicted).item() >= model.classes:\n",
    "                predicted = predicted % model.classes\n",
    "        else:\n",
    "            scores = model(data) if (allowed_classes is None) else model(data)[:, allowed_classes[2]]\n",
    "            #print(scores)\n",
    "\n",
    "            '''\n",
    "            if get_valid_loss:\n",
    "                # Calculate prediction loss\n",
    "                if args.bce:\n",
    "                    # -binary prediction loss\n",
    "                    binary_targets = utils.to_one_hot(y.cpu(), y_hat.size(1)).to(y.device)\n",
    "                    if self.binaryCE_distill and (scores is not None):\n",
    "                        classes_per_task = int(y_hat.size(1) / task)\n",
    "                        binary_targets = binary_targets[:, -(classes_per_task):]\n",
    "                        binary_targets = torch.cat([torch.sigmoid(scores / self.KD_temp), binary_targets], dim=1)\n",
    "                    predL = None if y is None else F.binary_cross_entropy_with_logits(\n",
    "                        input=y_hat, target=binary_targets, reduction='none'\n",
    "                    ).sum(dim=1).mean()     #--> sum over classes, then average over batch\n",
    "                else:\n",
    "                    # -multiclass prediction loss\n",
    "                    predL = None if y is None else F.cross_entropy(input=y_hat, target=y, reduction='mean')\n",
    "            '''\n",
    "            # for rocauc score\n",
    "            '''\n",
    "            print(scores.shape)\n",
    "            cnt = 0\n",
    "            for i in scores:\n",
    "                detached_i = i.cpu().detach().numpy()\n",
    "                pre_normal_i = [(float(k)-min(detached_i))/(max(detached_i)-min(detached_i)) for k in detached_i]\n",
    "                normal_i = [np.float(j)/sum(pre_normal_i) for j in pre_normal_i]\n",
    "                print(normal_i)\n",
    "                if  cnt == 2:\n",
    "                    break\n",
    "                cnt += 1\n",
    "                #print(sum(normal_i))\n",
    "                y_predicts_scores.append(np.array(normal_i))\n",
    "            '''\n",
    "            predicted_scores_, predicted = torch.max(scores, 1)\n",
    "            #print(labels, predicted_scores_)\n",
    "            \n",
    "            #print(list(predicted_scores_.detach().cpu().numpy()))\n",
    "            \n",
    "            print(roc_auc_score(np.array(list(labels.detach().cpu().numpy())),\\\n",
    "                                np.array(list(predicted_scores_.detach().cpu().numpy())), average=\"weighted\"))\n",
    "            print(f'*************************')\n",
    "        if cnt == 1:\n",
    "            break\n",
    "        cnt += 1\n",
    "        \n",
    "    # -update statistics\n",
    "    total_correct += (predicted == labels).sum().item()\n",
    "    total_tested += len(data)\n",
    "\n",
    "    correct_labels += list(labels.cpu().numpy())\n",
    "    predicted_labels += list(predicted.cpu().numpy())\n",
    "\n",
    "precision = total_correct / total_tested\n",
    "#y_predicts_scores = np.array(y_predicts_scores)\n",
    "correct_labels = np.array(correct_labels)\n",
    "\n",
    "#print(len(correct_labels), np.unique(correct_labels), len(y_predicts_scores))\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "f1score = f1_score(correct_labels, np.array(predicted_labels), average='weighted')\n",
    "\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
    "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
    "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
    "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
    "        0, 0, 0, 0, 1, 0, 0, 0]\n",
    "pred_scores = [-2.8513, -4.2416, -3.2387, -2.5339, -4.5395, -1.0418, -1.5333, -3.8420,\n",
    "        -2.5339, -3.2387, -1.3832, -3.8420, -4.2416, -3.2864, -3.8420, -3.8420,\n",
    "        -1.8740, -3.8420, -3.6477, -3.8420, -1.6273, -1.1597, -1.8740, -2.0459,\n",
    "        -5.9519, -4.8213, -5.9631, -3.2286, -4.4020, -1.5333, -2.1682, -3.9239,\n",
    "        -3.6596, -4.2416, -2.8135, -4.1119, -1.8740, -1.1597, -1.1597, -2.2283,\n",
    "        -2.2475, -2.6085, -1.8071, -2.5339, -1.3832, -1.1597, -3.8420, -1.8309,\n",
    "        -5.7794, -1.4302, -1.5333, -2.9973, -1.5333,  2.9774, -4.2416, -2.7060,\n",
    "        -2.9623, -3.4273, -2.1682, -1.5410, -5.3012, -4.2416, -3.5232, -3.8524,\n",
    "         0.0561, -6.1545, -3.2387, -5.8473, -3.8420, -1.8309, -3.5232, -3.9449,\n",
    "        -1.5410, -1.5410, -3.8388, -3.2698, -0.8056, -1.8740, -1.8740, -1.0878,\n",
    "        -5.3578, -5.8473, -2.0491, -3.8420, -1.4302, -2.1682, -3.5232, -2.9498,\n",
    "        -2.6485, -0.8032, -1.3832, -5.5392, -5.3578, -5.4002, -1.8309, -1.3832,\n",
    "        -3.8420, -2.0195, -2.3809, -5.3578, -2.6233, -3.0559, -2.5773, -3.8420,\n",
    "        -5.5608, -3.2864, -4.8213, -1.8740, -3.6734, -1.1597, -2.0195, -1.0418,\n",
    "        -5.3578, -3.8420, -3.8420, -1.8309, -4.2416, -4.6601, -1.1405, -3.1656,\n",
    "        -2.1682,  0.2496, -2.0195, -1.8309, -3.5931, -1.3832, -1.8309, -3.8420]\n",
    "\n",
    "pred_y = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
    "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
    "        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
    "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
    "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
    "        0, 1, 1, 0, 0, 1, 0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-2.9495916 -2.6232998 -5.357806  -1.4302052 -4.2416    -2.9497511\n",
    " -1.8740026 -4.729642  -3.3140519 -3.06669   -1.3224517 -3.6595647\n",
    " -3.2488108 -1.8309349 -3.8419578 -2.5772731 -4.940881  -1.8309349\n",
    " -1.383226  -1.4302052 -1.1217191 -1.5332726 -1.8309349 -1.8309349\n",
    " -3.2863524 -1.0058535 -2.1681511 -5.242112  -3.8419578 -5.560781\n",
    " -2.0195115 -2.1681511 -1.8740026 -4.0942135 -1.1217191 -2.1681511\n",
    " -3.8419578 -3.8419578 -2.1681511 -1.5409576 -1.5332726 -2.228278\n",
    " -3.9365633 -1.1597215 -2.0195115 -0.4404592 -4.2416    -5.391906\n",
    " -1.8309349 -4.2416    -3.8419578  2.9774342 -1.1597215 -3.5232313\n",
    " -3.8300388 -1.383226  -4.2416    -5.357806  -1.5332726 -2.851251\n",
    " -1.8309349 -3.5931199 -4.2416    -3.7794015 -2.1681511 -2.1681511\n",
    " -5.568199  -1.1597215 -3.9449384 -1.4302052 -3.8419578 -2.0195115\n",
    " -2.5338743 -5.357806  -2.1681511 -4.1211853 -3.611037  -5.9519386\n",
    " -2.2474952 -2.9623084 -2.1681511 -3.621124  -4.8211236 -1.9454943\n",
    " -2.1681511 -3.8419578 -3.8419578 -3.5218563 -1.3224517 -2.0491047\n",
    " -4.2416    -4.2416    -1.8740026 -3.8419578 -4.2416    -2.5259635\n",
    " -4.8212533 -1.8309349 -3.1655557 -3.8419578 -2.1681511 -4.5575304\n",
    " -3.2697926 -1.1404768 -1.1597215 -1.8309349 -2.1681511 -4.4020314\n",
    " -5.963054  -2.9497511 -3.8419578 -1.0418016 -1.8309349 -4.2416\n",
    " -1.383226  -5.683167  -2.045892  -5.8472857 -1.383226  -4.2416\n",
    " -3.8419578 -3.8388011 -5.357806  -1.4302052 -3.8419578 -3.3299155\n",
    " -3.8419578 -6.1544576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(true_y), type(pred_y), f1_score(np.array(true_y), np.array(pred_y), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(true_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(np.array(true_y), np.array(pred_scores), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
